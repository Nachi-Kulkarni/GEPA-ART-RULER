# GEPA + LangGraph ART + RULER Integration

## ðŸŽ¯ Project Overview

Advanced competitive programming AI system combining:
- **GEPA**: Genetic prompt optimization
- **LangGraph ART**: Reinforcement learning agents with tool use
- **RULER**: Error analysis and reward shaping

## ðŸ“Š Training Data

### External Training Sources (1500+ problems)
- **Codeforces**: 500 problems (GEPA optimization)
- **AtCoder**: 500 problems (RL training)  
- **USACO**: 500 problems (RL training)

### Evaluation Data
- **OJBench**: 232 problems (NOI + ICPC)
- **Never used in training** - ensures valid evaluation

## ðŸš€ Quick Start

### 1. Install Dependencies
```bash
# Core dependencies
pip install -r requirements.txt

# LangGraph + OpenPipe
pip install langgraph langchain langchain-community openpipe

# PyTorch (for production)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers accelerate datasets
```

### 2. Load Training Data
```python
from training_data import load_external_training_data

# Load complete training dataset
dataset = load_external_training_data(gepa_size=500, rl_size=1000)
```

### 3. Run Training Pipeline
```python
from langgraph_art import LangGraphARTAgent, create_rl_trainer
from langgraph_art.ruler_reward_shaper import create_ruler_reward_shaper

# Initialize components
agent = LangGraphARTAgent(enable_openpipe=True)
trainer = create_rl_trainer(agent)
ruler_shaper = create_ruler_reward_shaper()

# Run training iteration
await trainer.train_iteration(
    train_problems=dataset['rl_train'],
    val_problems=dataset['rl_val'],
    optimized_prompt=gepa_optimized_prompt
)
```

## ðŸ“‚ Project Structure

```
GEPA_ART_RULER/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ langgraph_art/          # LangGraph RL agents
â”‚   â”œâ”€â”€ training_data/          # External data loaders
â”‚   â”œâ”€â”€ gepa/                   # GEPA optimization
â”‚   â”œâ”€â”€ ruler/                  # RULER error analysis
â”‚   â”œâ”€â”€ art/                    # Original ART solver
â”‚   â”œâ”€â”€ models/                 # Model interfaces
â”‚   â””â”€â”€ evaluation/             # OJBench integration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ final_datasets/         # Training splits
â”‚   â”œâ”€â”€ cache/                  # Cached results
â”‚   â””â”€â”€ results/               # Evaluation results
â”œâ”€â”€ OJBench/                   # Evaluation benchmark
â”œâ”€â”€ gepa/                      # GEPA framework
â””â”€â”€ docs/                      # Documentation
```

## ðŸŽ¯ System Workflow

1. **GEPA Phase**: Optimize prompts on Codeforces problems
2. **RL Training**: Train agents on AtCoder/USACO problems
3. **RULER Enhancement**: Shape rewards with error analysis
4. **Evaluation**: Test on unseen OJBench problems

## ðŸ“ˆ Expected Performance

- **Baseline**: 17.9% (Qwen3-4B on OJBench)
- **Target**: 35-60% (with GEPA+RL+RULER)
- **Continuous Improvement**: Performance grows with training

## ðŸ”§ Production Deployment

1. Enable GPU training with real models
2. Scale to full datasets (1500+ training problems)
3. Enable OpenPipe cloud RL training
4. Run comprehensive evaluation on OJBench

## ðŸ§ª Key Features

- **Data Separation**: Proper train/test splits
- **Multi-Modal Learning**: Genetic + RL optimization
- **Error-Guided Learning**: RULER reward shaping
- **Tool Integration**: OJBench evaluation tools
- **Scalable Architecture**: Production-ready components

## ðŸ“‹ Status

âœ… **Core Implementation**: Complete
âœ… **Training Data**: 1500+ problems collected
âœ… **LangGraph Integration**: Functional
âœ… **RULER Enhancement**: Implemented
ðŸ”„ **Production Training**: Ready to deploy
